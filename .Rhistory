tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col,add=TRUE){
pred.nn <- performance(prediction(prob, label), 'tpr', 'fpr')
plot(pred.nn, col=col, add=add)
abline(a=0,b=1)
auc <- performance(prediction(prob, label), 'auc')@y.values[[1]]
return (auc)
}
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1], add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2], add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3], add=TRUE)
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
fit.xgboost.tree.test.prob <- predict(fit.xgboost.tree, test_matrix)
Y.test.Id <- rep(c(1:3), nrow(test_matrix))
high <- fit.xgboost.tree.test.prob[Y.test.Id==1]
low <- fit.xgboost.tree.test.prob[Y.test.Id==2]
medium <- fit.xgboost.tree.test.prob[Y.test.Id==3]
fit.xgboost.tree.test.class <- data.frame(high, low, medium)
tree.test.result <- factor(apply(fit.xgboost.tree.test.class,1, function(x) which.max(x)-1))
levels(tree.test.result) <- c("high", "low", "medium")
tree.predict.test.result <- data.frame(actual = test.data$interest_level,
predict = tree.test.result)
tree.test.error <- mean(tree.test.result==as.factor(test.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.test.result))), 4),
smain=paste0('Accuracy: ',round(tree.test.error,2)), highlight = TRUE, colorbar = TRUE)
roc.test <- list()
roc.test$prob <- list(high=high, low=low, medium=medium)
roc.test$class <- list(
high = as.numeric(label.test == "high"),
low = as.numeric(label.test == "low"),
medium = as.numeric(label.test == "medium")
)
high.test.auc <- plotRoc(high, as.numeric(label.test == "high"), col = col[1], add=FALSE)
low.test.auc <- plotRoc(low, as.numeric(label.test == "low"), col = col[2], add=TRUE)
medium.test.auc <- plotRoc(medium, as.numeric(label.test == "medium"), col = col[3], add=TRUE)
legend("bottomright", legend=c(
paste0("high-test: ", round(high.test.auc, 4)),
paste0("low-test: ", round(low.test.auc, 4)),
paste0("medium-test: ", round(medium.test.auc, 4))),
col=col[1:3], lwd=2)
fit.xgboost.tree.train.prob <- predict(fit.xgboost.tree, train_matrix)
Y.train.Id <- rep(c(1:3), nrow(train_matrix))
high <- fit.xgboost.tree.train.prob[Y.train.Id==1]
low <- fit.xgboost.tree.train.prob[Y.train.Id==2]
medium <- fit.xgboost.tree.train.prob[Y.train.Id==3]
fit.xgboost.tree.train.class <- data.frame(high, low, medium)
tree.train.result <- factor(apply(fit.xgboost.tree.train.class,1, function(x) which.max(x)-1))
levels(tree.train.result) <- c("high", "low", "medium")
tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Train Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col,add=TRUE){
pred.nn <- performance(prediction(prob, label), 'tpr', 'fpr')
plot(pred.nn, col=col, add=add)
abline(a=0,b=1)
auc <- performance(prediction(prob, label), 'auc')@y.values[[1]]
return (auc)
}
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1], add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2], add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3], add=TRUE)
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1], add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2], add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3], add=TRUE)
par(new)
fit.xgboost.tree.train.prob <- predict(fit.xgboost.tree, train_matrix)
Y.train.Id <- rep(c(1:3), nrow(train_matrix))
high <- fit.xgboost.tree.train.prob[Y.train.Id==1]
low <- fit.xgboost.tree.train.prob[Y.train.Id==2]
medium <- fit.xgboost.tree.train.prob[Y.train.Id==3]
fit.xgboost.tree.train.class <- data.frame(high, low, medium)
tree.train.result <- factor(apply(fit.xgboost.tree.train.class,1, function(x) which.max(x)-1))
levels(tree.train.result) <- c("high", "low", "medium")
tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Train Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col){
pred.nn <- performance(prediction(prob, label), 'tpr', 'fpr')
plot(pred.nn, col=col)
abline(a=0,b=1)
auc <- performance(prediction(prob, label), 'auc')@y.values[[1]]
return (auc)
}
par(new=FALSE)
par(new=TRUE)
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1])
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2])
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3])
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
par(new=FALSE)
plot.table(round(as.matrix(prop.table(table(tree.predict.test.result))), 4),
smain=paste0('Accuracy: ',round(tree.test.error,2)), highlight = TRUE, colorbar = TRUE)
fit.xgboost.tree.test.prob <- predict(fit.xgboost.tree, test_matrix)
Y.test.Id <- rep(c(1:3), nrow(test_matrix))
high <- fit.xgboost.tree.test.prob[Y.test.Id==1]
low <- fit.xgboost.tree.test.prob[Y.test.Id==2]
medium <- fit.xgboost.tree.test.prob[Y.test.Id==3]
fit.xgboost.tree.test.class <- data.frame(high, low, medium)
tree.test.result <- factor(apply(fit.xgboost.tree.test.class,1, function(x) which.max(x)-1))
levels(tree.test.result) <- c("high", "low", "medium")
tree.predict.test.result <- data.frame(actual = test.data$interest_level,
predict = tree.test.result)
tree.test.error <- mean(tree.test.result==as.factor(test.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.test.result))), 4),
smain=paste0('Test Accuracy: ',round(tree.test.error,2)), highlight = TRUE, colorbar = TRUE)
par(new=FALSE)
high.test.auc <- plotRoc(high, as.numeric(label.test == "high"), col = col[1],add=FALSE)
plotRoc <- function(prob, label, col,add=TRUE){
prep <- prediction(prob, label)
pred.nn <- performance(prep, 'tpr', 'fpr')
plot(pred.nn, col=col,add=TRUE)
abline(a=0,b=1)
auc <- performance(prep, 'auc')@y.values[[1]]
return (auc)
}
fit.xgboost.tree.train.prob <- predict(fit.xgboost.tree, train_matrix)
Y.train.Id <- rep(c(1:3), nrow(train_matrix))
high <- fit.xgboost.tree.train.prob[Y.train.Id==1]
low <- fit.xgboost.tree.train.prob[Y.train.Id==2]
medium <- fit.xgboost.tree.train.prob[Y.train.Id==3]
fit.xgboost.tree.train.class <- data.frame(high, low, medium)
tree.train.result <- factor(apply(fit.xgboost.tree.train.class,1, function(x) which.max(x)-1))
levels(tree.train.result) <- c("high", "low", "medium")
tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Train Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col,add=TRUE){
prep <- prediction(prob, label)
pred.nn <- performance(prep, 'tpr', 'fpr')
plot(pred.nn, col=col,add=TRUE)
abline(a=0,b=1)
auc <- performance(prep, 'auc')@y.values[[1]]
return (auc)
}
par(new=FALSE)
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1],add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2],add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3],add=TRUE)
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1],add=FALSE)
plotRoc <- function(prob, label, col,add=TRUE){
par(new=FALSE)
prep <- prediction(prob, label)
pred.nn <- performance(prep, 'tpr', 'fpr')
plot(pred.nn, col=col,add=TRUE)
abline(a=0,b=1)
auc <- performance(prep, 'auc')@y.values[[1]]
return (auc)
}
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1],add=FALSE)
fit.xgboost.tree.train.prob <- predict(fit.xgboost.tree, train_matrix)
Y.train.Id <- rep(c(1:3), nrow(train_matrix))
high <- fit.xgboost.tree.train.prob[Y.train.Id==1]
low <- fit.xgboost.tree.train.prob[Y.train.Id==2]
medium <- fit.xgboost.tree.train.prob[Y.train.Id==3]
fit.xgboost.tree.train.class <- data.frame(high, low, medium)
tree.train.result <- factor(apply(fit.xgboost.tree.train.class,1, function(x) which.max(x)-1))
levels(tree.train.result) <- c("high", "low", "medium")
tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Train Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col,add=TRUE){
par(new=FALSE)
prep <- prediction(prob, label)
pred.nn <- performance(prep, 'tpr', 'fpr')
plot(pred.nn, col=col,add=TRUE)
if(!add) abline(a=0,b=1)
auc <- performance(prep, 'auc')@y.values[[1]]
return (auc)
}
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1],add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2],add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3],add=TRUE)
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
fit.xgboost.tree.train.prob <- predict(fit.xgboost.tree, train_matrix)
Y.train.Id <- rep(c(1:3), nrow(train_matrix))
high <- fit.xgboost.tree.train.prob[Y.train.Id==1]
low <- fit.xgboost.tree.train.prob[Y.train.Id==2]
medium <- fit.xgboost.tree.train.prob[Y.train.Id==3]
fit.xgboost.tree.train.class <- data.frame(high, low, medium)
tree.train.result <- factor(apply(fit.xgboost.tree.train.class,1, function(x) which.max(x)-1))
levels(tree.train.result) <- c("high", "low", "medium")
tree.predict.result <- data.frame(actual = train.data$interest_level,
predict = tree.train.result)
tree.train.error <- mean(tree.train.result==as.factor(train.data$interest_level))
plot.table(round(as.matrix(prop.table(table(tree.predict.result))), 4),
smain=paste0('Train Accuracy: ',round(tree.train.error,2)), highlight = TRUE, colorbar = TRUE)
col <- sample(rainbow(500), 5)
plotRoc <- function(prob, label, col,add=TRUE){
prep <- prediction(prob, label)
pred.nn <- performance(prep, 'tpr', 'fpr')
plot(pred.nn, col=col,add=TRUE)
if(!add) abline(a=0,b=1)
auc <- performance(prep, 'auc')@y.values[[1]]
return (auc)
}
high.train.auc <- plotRoc(high, as.numeric(label.train == "high"), col = col[1],add=FALSE)
low.train.auc <- plotRoc(low, as.numeric(label.train == "low"), col = col[2],add=TRUE)
medium.train.auc <- plotRoc(medium, as.numeric(label.train == "medium"), col = col[3],add=TRUE)
legend("bottomright", legend=c(
paste0("high-train: ", round(high.train.auc, 4)),
paste0("low-train: ", round(low.train.auc, 4)),
paste0("medium-train: ", round(medium.train.auc, 4))),
col=col[1:3], lwd=2)
## data import
packages <- c("jsonlite", "dplyr", "purrr", "tidytext", "ggplot2", "ggthemes",
"rpart.plot", "RecordLinkage","sampling", "caret", "xgboost",
"pROC", "ROCR")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# "rattle",
read.fromJson <- function(filepath){
data <- fromJSON(filepath)
var <- setdiff(names(data), c("photos","features"))
data <- map_at(data, var, unlist) %>%
tibble::as_tibble(.) %>%
mutate(feature_count = lengths(features)) %>%
mutate(photo_count = lengths(photos)) %>%
select(-features, -photos) %>%
data.frame
}
rental_data <- read.fromJson("train.json")
colnames(rental_data)
test_data <- read.fromJson("test.json")
colnames(test_data)
View(test_data)
test_data$listing_id
listing_id <- read.fromJson("test.json")$listing_id
listing_id[1]
## data import
packages <- c("jsonlite", "dplyr", "purrr", "tidytext", "ggplot2", "ggthemes",
"rpart.plot", "RecordLinkage","sampling", "caret", "xgboost",
"pROC", "ROCR")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# "rattle",
read.fromJson <- function(filepath){
data <- fromJSON(filepath)
var <- setdiff(names(data), c("photos","features"))
data <- map_at(data, var, unlist) %>%
tibble::as_tibble(.) %>%
mutate(feature_count = lengths(features)) %>%
mutate(photo_count = lengths(photos)) %>%
select(-features, -photos) %>%
data.frame
}
rental_data <- read.fromJson("train.json")
packages <- c("jsonlite", "dplyr", "purrr", "tidytext", "ggplot2", "ggthemes",
"RecordLinkage","sampling", "xgboost", "RCurl", "ROCR")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# "rattle",
read.fromJson <- function(filepath){
data <- fromJSON(filepath)
var <- setdiff(names(data), c("photos","features"))
data <- map_at(data, var, unlist) %>%
tibble::as_tibble(.) %>%
mutate(feature_count = lengths(features)) %>%
mutate(photo_count = lengths(photos)) %>%
select(-features, -photos) %>%
data.frame
}
rental_data <- read.fromJson("train.json")
## data exploration
glimpse(rental_data)
theme_set(theme_economist())
plot.theme <- theme(
legend.position = "bottom",
axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
axis.title = element_text(size=16, vjust=3),
plot.title = element_text(hjust = 0.5)
)
rental_data %>%
group_by(interest_level) %>%
count() %>%
arrange(desc(n)) %>%
ggplot(aes(x=interest_level, y=n, fill=interest_level)) +
geom_bar(stat="identity") +
labs(x = "interest level", y = "Freq", title = "The distribution of interse level") +
geom_text(aes(label = n, vjust=-0.2)) +
plot.theme
rental_data %>%
group_by(interest_level, bathrooms) %>%
count() %>%
arrange(desc(bathrooms)) %>%
ggplot(aes(x=as.character(bathrooms), y=n, fill=bathrooms)) +
geom_bar(stat="identity") +
facet_wrap(~interest_level) +
coord_flip() +
labs(x = "bath room count", y = "Freq", title = "The distribution of bath rooms number by interest level") +
geom_text(aes(label = n, hjust=-0.2)) +
plot.theme
rental_data %>%
group_by(interest_level, feature_count) %>%
count() %>%
arrange(desc(feature_count)) %>%
ggplot(aes(x=as.factor(feature_count), y=n, fill=feature_count)) +
geom_bar(stat="identity") +
facet_wrap(~interest_level) +
coord_flip() +
labs(x = "feature count", y = "Freq", title = "fatures count interset level") +
geom_text(aes(label = n, hjust=0.5)) +
theme(legend.position = "bottom")  +
plot.theme
rental_data %>%
group_by(interest_level, photo_count) %>%
count() %>%
arrange(desc(photo_count)) %>%
ggplot(aes(x=as.factor(photo_count), y=n, fill=photo_count)) +
geom_bar(stat="identity") +
facet_wrap(~interest_level) +
coord_flip() +
labs(x = "photo count", y = "Freq", title = "photos count by interset level") +
geom_text(aes(label = n, hjust=-0.2)) +
plot.theme
detect_outlier <- function(column) {
iqr = quantile(column, .75) - quantile(column, .25)
low = quantile(column, .25) - 1.5 * iqr
high = quantile(column, .75) + 1.5 * iqr
outlier_index = ifelse(column < low | column > high, TRUE, FALSE)
results <- list("index" = outlier_index, "values"  = column[outlier_index], 'low' = low, 'high' = high, 'iqr' = iqr)
return(results)
}
rental_data %>%
ggplot(aes(x=interest_level, y=price)) +
geom_violin((aes(fill = interest_level))) +
geom_boxplot(width=.1, fill="black", outlier.color="red") +
stat_summary(fun.y=median, geom="point",
fill="blue", shape=21, size=2.5) +
ylim(0, quantile(rental_data$price, .99)) +
plot.theme
rental_data %>%
ggplot(aes(x=interest_level, y=longitude)) +
geom_violin((aes(fill = interest_level))) +
geom_boxplot(width=.1, fill="black", outlier.color="red") +
stat_summary(fun.y=median, geom="point",
fill="blue", shape=21, size=2.5) +
ylim(0, quantile(rental_data$longitude, .99)) +
plot.theme
rental_data %>%
ggplot(aes(x=interest_level, y=latitude)) +
geom_violin((aes(fill = interest_level))) +
geom_boxplot(width=.1, fill="black", outlier.color="red") +
stat_summary(fun.y=median, geom="point",
fill="blue", shape=21, size=2.5) +
ylim(0, quantile(rental_data$latitude, .99)) +
plot.theme
# From the numer plot, we should deal with the outlier observations.
rental_data <- rental_data %>%
filter(!detect_outlier(price)$index) %>%
filter(!detect_outlier(latitude)$index) %>%
filter(!detect_outlier(longitude)$index)
rental_data %>%
ggplot(aes(x=price, y=..density..)) +
geom_histogram(fill="cornsilk", colour="red", size=.2,
binwidth = diff(range(rental_data$price))/20) +
geom_density() +
facet_grid(.~interest_level) +
labs(title = "The distribution of price by interset level") +
plot.theme
rental_data %>%
ggplot(aes(x=latitude, y=..density..)) +
geom_histogram(fill="cornsilk", colour="red", size=.2,
binwidth = diff(range(rental_data$latitude))/20) +
geom_density() +
facet_grid(.~interest_level) +
labs(title = "The distribution of latitude by interset level") +
plot.theme
rental_data %>%
ggplot(aes(x=longitude, y=..density..)) +
geom_histogram(fill="cornsilk", colour="red", size=.2,
binwidth = diff(range(rental_data$longitude))/20) +
geom_density() +
facet_grid(.~interest_level) +
labs(title = "The distribution of latitude by interset level") +
plot.theme
# Variable Transform
##1. Creating Features from Street Address and Display Address
rental_data <- rental_data %>%
mutate(distance = levenshteinSim(tolower(street_address),tolower(display_address))) %>%
select(bathrooms, bedrooms,latitude, longitude, price, interest_level, feature_count, photo_count, distance)
na.omit(rental_data) %>%
ggplot(aes(x=distance, y=..density..)) +
geom_histogram(fill="cornsilk", colour="red", size=.2) +
geom_density() +
facet_grid(.~interest_level) +
labs(title = "The distribution of distance by interset level") +
plot.theme
sample.flag <- strata(rental_data, stratanames = "interest_level",
size = 3*rep(min(table(rental_data$interest_level)),3),
method = "srswr")
## data partition
rental_data <- na.omit(rental_data)
train.data <- na.omit(rental_data[sample.flag$ID_unit,]) %>%
mutate(interest_level = factor(interest_level)) %>%
sample_frac(1)
test.data <- na.omit(rental_data[-sample.flag$ID_unit,]) %>%
mutate(interest_level = factor(interest_level)) %>%
sample_frac(1)
train_matrix <- Matrix::sparse.model.matrix(interest_level ~ .-1, data = train.data)
test_matrix <- Matrix::sparse.model.matrix(interest_level ~ .-1, data = test.data)
dtrain <- xgb.DMatrix(train_matrix,
label = as.integer(as.factor(train.data$interest_level))-1)
dtest <- xgb.DMatrix(test_matrix, label = as.integer(as.factor(test.data$interest_level))-1)
label.train <- train.data$interest_level
label.test <- test.data$interest_level
param <- list(objective = "multi:softprob",
booster="gbtree", eval_metric = "merror",
max.depth = 20,eta = 0.1, nthread =8,
alpha=0.01)
watchlist <- list(eval = dtest, train = dtrain)
system.time(
fit.xgboost.tree <- xgb.train(
nrounds = 20,
verbose = 1,
params = param,
num_class = 3,
dtrain,
watchlist)
)
system.time(
fit.xgboost.tree <- xgb.train(
nrounds = 50,
verbose = 1,
params = param,
num_class = 3,
dtrain,
watchlist)
)
predict_data <- read.fromJson("test.json")
dim(predict_data)
dim(na.omit(predict_data))
predict_data <- read.fromJson("test.json") %>%
mutate(distance = levenshteinSim(tolower(street_address),tolower(display_address))) %>%
select(bathrooms, bedrooms,latitude, longitude, price, feature_count, photo_count, distance) %>%
mutate(interest_level = " ")
predict.matrix <- Matrix::sparse.model.matrix(interest_level ~ .-1, data = predict_data)
tree.predict <- predict(fit.xgboost.tree, predict.matrix)
dim(tree.predict)
length(tree.predict)
Y.tag = 1:length(tree.predict) %%3 + 1
high <- tree.predict[Y.tag==2]
low <- tree.predict[Y.tag==3]
medium <- tree.predict[Y.tag==1]
listing_id <- read.fromJson("test.json")$listing_id
tree.predict.df <- data.frame(listing_id, high, low, medium)
length(tree.predict)
length(listing_id)
length(Y.tag)
length(Y.tag)/3
dim(predict.matrix)
table(predict_data$interest_level)
dim(na.omit(predict_data))
View(predict_data)
na.fail(predict_data$bathrooms)
na.fail(predict_data$bedrooms)
na.fail(predict_data$longitude)
na.fail(predict_data$distance)
a <- 1:10
ifelse(a > 2, 0, a)
predict_data <- read.fromJson("test.json") %>%
mutate(distance = levenshteinSim(tolower(street_address),tolower(display_address))) %>%
mutate(distance = ifelse(is.na(distance), 0, distance)) %>%
select(bathrooms, bedrooms,latitude, longitude, price, feature_count, photo_count, distance) %>%
mutate(interest_level = " ")
predict.matrix <- Matrix::sparse.model.matrix(interest_level ~ .-1, data = predict_data)
tree.predict <- predict(fit.xgboost.tree, predict.matrix)
Y.tag = 1:length(tree.predict) %%3 + 1
high <- tree.predict[Y.tag==2]
low <- tree.predict[Y.tag==3]
medium <- tree.predict[Y.tag==1]
listing_id <- read.fromJson("test.json")$listing_id
tree.predict.df <- data.frame(listing_id, high, low, medium)
write.csv(tree.predict.df, "predict_df.csv",row.names = FALSE)
